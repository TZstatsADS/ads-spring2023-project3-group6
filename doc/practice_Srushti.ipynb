{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c1052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install opencv-python\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58c70a",
   "metadata": {},
   "source": [
    "## 1. Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f1ebd",
   "metadata": {},
   "source": [
    "For the project, we provide a training set with 50000 images in the directory `../data/images/` with:\n",
    "- noisy labels for all images provided in `../data/noisy_label.csv`;\n",
    "- clean labels for the first 10000 images provided in `../data/clean_labels.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d7d21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 3]\n"
     ]
    }
   ],
   "source": [
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\", skip_header=10000)\n",
    "# Reading the remaining 40000 labels, excluding the first 10000 labels\n",
    "print(noisy_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1caec517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images\n",
    "n_img = 50000\n",
    "all_imgs = np.empty((n_img, 32, 32, 3))\n",
    "\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    all_imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4868e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) (40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "clean_imgs = all_imgs[:10000,:,:,:]\n",
    "noisy_imgs = all_imgs[10000:,:,:,:]\n",
    "\n",
    "print(clean_imgs.shape, noisy_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d05307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f865424b2e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAACbCAYAAACwNiQ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoIklEQVR4nO2de3Bc1Zngv3tvv1ut1rsloYdlIx7GYBJhMzgOjySYIczWsFtTxSTZpLKzWxUDpuLxJsRUbQqTmgWSqUptzSSER4KnNrsJeeCqULVsNpqBGIhDAIPf4Ad+INlSZL1bUj/vPfuHpPt932l12zLSdVv+flUun+5z+t7b954+Ot/bUEopEARB8ADzYl+AIAiXD7LgCILgGbLgCILgGbLgCILgGbLgCILgGbLgCILgGbLgCILgGbLgCILgGbLgCILgGbLgCILgGYu24Dz11FPQ0dEBoVAIurq64PXXX1+sUwlliswBQce3GAf9xS9+AZs3b4annnoKPvWpT8EzzzwDd999Nxw6dAja2tpKftZxHDhz5gzEYjEwDGMxLk9YQJRSkEwmobm5GUwT/359nDkAIPPgUqPYPJhr4IKzdu1atXHjRvbeNddco7Zu3XrOz/b09CgAkH+X2L+enp4FmwMyDy7df/o80FnwHU42m4Xdu3fD1q1b2fsbNmyAXbt2FYzPZDKQyWTc12omeL29vgFM04R0PsfGO8px24Yi79s2H+dgp/4H0rTm/ouptMB5k3xQAZ6366ZPsHHLV7ST8zqszzKDeB2Ax9P/agcDOM7nx/bY2DAbl8/jvYpWVLI+wxd12/F43G1PTk6ycdHKKjwX+V7JcX4uyx/CY2cmWF82O32/M9ks/I9nfwyxWIz0zW8OABSfB9WxyJw7HEXvM+nX/7qa/JEuAOSAhlN82HliKG03oMicI8d3DP5F6Gul3R/DwZ+13yY/cYP/lpSJrx061wuWBQsPAfp3nr4ORykYGZ9k82AuFnzBGRwcBNu2IZFIsPcTiQT09/cXjH/iiSfgscceK3jfNE33H4M9b/pCm5RG8S6zyBZdn5t8wcG238dvWzAQcNsFC46Ffee74PjJgpMmxwYAMMkvKBjkfYYPPxcK4WKRz+fZONpHF5xcJsjGWQGy4ACfrIZha6/x+8x3DgAUnweGYcz5vOgPhJ5bH7uoVpEFEPXonJh9Zxa2kBQfxu4FAL8HpkHugDaOH3/uua6frPB6tZHnuCeLosOZ68RKqTkv5pFHHoEtW7a4r8fHx6G1tRWaWxLg81lwqreHjR8bx7/WPgNXXou0AQCMEn/a6C6JXyR/aZMdjyKdsRjfWcRjNW47m+M/TIssHtEo7kBA20191IPfMxKJuO1E0xX8mhxcPAyTLziWv4IcHo/vD0TZOJt8/ZGh0257cnSIjUtn8btYWb7DydnTz1L/vpTznQMAxefBUkcZ/I8BsF0NGaf/0NliobQu+seAfu5Cd2SqSHv+LPiCU1dXB5ZlFfwlGxgYKPiLBwAQDAYhGAwWvC9cusx3DgDIPLhcWPAdZyAQgK6uLuju7mbvd3d3w7p16xb6dEIZInNAKMaiiFRbtmyBL3/5y3DTTTfBLbfcAs8++yx89NFHsHHjxsU4nVCGyBwQ5mJRFpz77rsPhoaG4Dvf+Q709fXBqlWr4OWXX4b29vZzf3iG5SuWQcDvh/GpJHt/ZGzUbTNpUrM80VcF1icTey2r+CbPJpYvg+iIQqEwG+ezUBSYnMyyvrHJcbcdJlYl3VKWzqEsHyHXFIjwc9l5lMMDwQjrC0XQMjU4OIjHq+CWA3ruM6Ojbvudt99h4yZz5FyOpquZ+c62Zh2cZSHmwOWA0vQvVFeogOoluY6SWrMMPS05fUn1OYauf6FKolLK3oUz9S2a0viBBx6ABx54YLEOL1wCyBwQdCSWShAEz1i0Hc7HJRqthGAgAPV1jez9yUl0Dsuk0ESu+8boYhTFIFtL6uejW2zpMRxio/T7/GycnzjIVVTwrW92chSPQY4XDnJR6bpVq8grFGWUttUNhtH0HdREqhwRexRxC8g6GTauIoDnjkXweL4AF70q4mjuD2jbccs/fYx8Pgfw/hFYLJRSC7ih//jQq5mPF47BHOvIN9KeryI/SQNwnimliVTEB820NJUBEFWAiW3qDDt9ruI+OouF7HAEQfAMWXAEQfCMshWpYpVxCAaD0NzMPW0N4qrd34feuaa2I8xk0Fqkh0dYJm5P6edsxS0u1PXbyeN2NBTmDmpVtVV4DM1xtDKPIkuexIXZOS7mJCfQk7e+noqRmvWNWLAsH98ip9N4fBpnZdvcwuQP4DEDJHTC9GnWt2i12w75+XX4Zsbmctwqt+AUEakWM4JcF8fpuZjfbkEYiyb2FIHOR1tz/qUe86ainuT8p2qRl7aT0q6XiORMvCr0/CZHLHHFxHJWRFVRSoVBkR2OIAieIQuOIAieIQuOIAieUbY6nNmMPrpcTCOuQyTYz9aUJxHioctC9AHAZ6K5cXIKTevjk1P8IqiegOQtmcyk2bDJDMrQ4XAV6wtScz35nO6h6/Ojiduw0MzuaHqlLNH9GD7te5HrtUiqCkNLcZHNovf2VAq/cz7PFQpOGr+Xz8eP4Zv1YDXm9jReMAzjnPqahdbnlMxYx7xzi39O1++YTH9CnpPmbmDnUSdm2yTi3+L33yHjlOLzMRTFOZcl12Hb/HtRfSi7igKPZHrlc9/r830CssMRBMEzZMERBMEzylak8vn94Pf7C0Qqasalmet08yw10xUEbxLTcpaINpksF8v8xBvYR0QUK8A9fPuGRt12KjPGj+HDa1yz5ia3red+OXr0qNueIn8HohF+Lr+BZvbUBA9sDRFbKd2qT2jjMhkUI7NZvG+6t3akGs3i0QruXR2OxmY+z837C40xT5GqcKyas1kKXaTiHuf4vs+n/3yIG4UmUlEJ2nHwhU8zVceieJ8jQVQfTCZ5mthIGH8Xd9zOU36svGGl2/6Xn/0ft338xBk2zmQJ3Fi4M3BUkXHzR3Y4giB4hiw4giB4hiw4giB4RtnqcBzbnjO5k8+HsqvfH5jzfQBudtbl6VglJqqayqDbfzLF9UA+P8rQFRVVbvvkmbNsXK6PlFexeHjA2pvX4zEaMEzj8OHDbNyYTWTjDF57z8BpNq6poc5t11XVsb7UKF6HA6hbCYS06g7kVD4fjUjmsnsyieEWjhatnJ2pBLHYoQ0fW4dTMm/43EodvfIDHeWQA+ZzXOdHz11N9F8AAH6ie0w0NLjttpYaNm7lVS1ue2Icn2FybJyNi4TxOurq+LO5cfVyt736IGYhOKHpcDRbOBSFFXcQs7ggCJcIsuAIguAZZStSKaVAKVUgDgX8KAIEAnj5uvQVChGzs7bfi1Sg2GMF8HiOtv5axKSdzuL+M61FhK/+izVu+xNrP836Gkldqb379rrtgTFuPo/XkNpWNol0177YO3sPuu07b13P+uJ1tW57cBi3z6apJQwLE3M/cTuglS8BAHIWehor7Tlk0tPerfkSdakWAkPZ5y6+Vio3r6IJrTQRinhJU++LXJZ7nOeI2F0Vw3nV3MRF2pvW3Oi2r732atbX1IgZAEZGR9z2+CCvu3bzjSgOnTyNdcL6zvJn6CNe5naOuz2kJ/FZBanHuZ7ES9GsCcSkX3C7abXbuQtTFuRVLoLscARB8AxZcARB8IyyFakMc+afZn1ySKIgZaIVSTlczsk7pAyw5q1smuitG68mff4GNi4UwnF+H56rMdHMxtVWNeF15Pl+9M99aNE6uO8Dt33mDLcYNDbjMfJkexrUAjSViVvknbveZn2f33Cr2zZDmICrr6+PjasMk9zFIWwHKirYOFL9BkJBPlXCMzmNc+ZiT6GPmdHYKOVBi6IC9Ziur61lo1Zff73bvu5qfPZNjXE2jlqm0lqAb3/fcbd9+nSv2+49xq2VuSSW9/nc5//abY9O7mPjIhGcj5kJPr/r61GMv+IKbAf8/FnlbeoZje/roqcq+mL+yA5HEATPkAVHEATPkAVHEATPKFsdjumzwPJZENCipcN+1E1MTOF6mU5xHU6A6DCqazXdDNFVxEntH7C46dFUJBl1HuVkRxNkjx9Hs+Spj/awPlpJOJskEdxD3AQ9amE0cCiM3zmnuCevo1Cxkkxzk/Srrx1y2zapUUWTjAEAqPyo2w6TCPO2qz7JxqWzOG5g4CTry+emj5nPaz4CF5mCWHGawMxwivatXn2t2/7LDXewcdQzOBTEz0xOjLBxaZoUS0v6NpXGvj/8cT+Oy3O3h+QU6vk+ffd/cNvHT33ExrUS3UznslbWlyLlpSvjOF/yNtcrOcTETUtZK/0uLmBhMNnhCILgGbLgCILgGWUrUgUCYQgEQ5DOjLL3x4fR+1IRD9qqBC8JnDbQm3ZY8YBKh5gRM2RLG7D49rYyhONs4v2bnOBiTpaYwu28ZlLMozhDEzuFwlrgJZF6MpMYNGnoYgBQ71guAh49iibVDMmznMtz8U3Z+DqfRq9aS6/f5cdzZ3ITrC9vTAeV2vmS0ZHeowUXWj58nUnz57ZmzTVu+z9+CcUXv1aDyybe1L4AEeNzvB7UkQ+Pue1TJ3jQ7W23fcZth4hJeyLJvZodP4r7vf041zNZPjdPnjzpttua+dzPkbnKcoRpYh4zf5coP6x/7uMgOxxBEDxDFhxBEDyjbEUq27HAdixIpfn2bmQUt/axGHp61iS4JepID+aG6R8aZn0BwC1yBSk7c2XnMjYubOI4h2w5hxW3zHxwGD1Hp9KaSEVziZD3HaWJIsTVU5EtsaNy2jB6bn6uLMnPkiflfWtJKWIAgFgFWi6GU2jRSI5xK0aWiAxZ58+sTwWm76ljL6AJYx4Uy8uitPtKPYjb27no8Xd/90W3HfChyHLs2AdsXCWxauZszGsTqeAW1EEyz1Z/klv86hPoSV5fj3PV9PMg3mVXdbrtsSTe/4weJGvhfe8/28+6WpdjTp3rb0DrW/MVCTautxev1yhZ6peiP+/55TiWHY4gCJ4hC44gCJ4hC44gCJ5RtjqcvAOQswGiFTxyN8LUDCivJ0eH2Dgzj+bGoM3zwYbyKLvWVaNsvf+tbjYuOYKR3pOTNMkRrylVU4cys5Pi5kuHeHBSs7jSZGEqCZsshyw/nkVM96bJjxGkZn3iRRu2uEl7qO+k256YQB1CoqGFjfORBGTDE9xbeWhy+h4azuLqcGZzGus6G9vGZ28Rd249YVskis/qb//2XtbnEM/bve+j928kyN0NUim8f4mmZW57cJh7Gq9YcaXbXrtmLes7sB/1QrEYesEfO8nN5339OOeGB7FdE+euHZ1X4nWYmvolnUV9zzXXr3bbXV03sHG9Pa/ii+IVjLUab/w5zLfKsuxwBEHwDFlwBEHwjLIVqc4ODkEgEGTJsgAAQiHc7poksDFNEhcBAFQF0XzZtIyLZfXVGPi2Zz/mCD7T38vGXXv1VW57dARFtvfe48mQ6poxKdM9n+WBf4qYp2kpG72cLHtt0nFsGPM0Bi2PbMDAx0nL+7766itsXGUERaVYGEWONV2fYOMmSBDg+8e4a8FwctoE75VINdf7s9Atvz72s5/5lNu+qpMHOZ4+jUmxquOYiCzo10SqSRS9DJLYLTnCxcxaUrZn77t7WJ9l4Xzs+gSKOWEtOHlgEOdZyI/fy6/NAyeP8+qmW3hu6yqSQMzyoSiW1Sr6UPHINGggZ2F5JrcPdJHKmHn//JAdjiAIniELjiAIniELjiAInlG2OpyqqhgEg0HIZnkYwcQ4miip+bhCSwBORfmWVu7S3dSIsvybb+/B9+t5eMTwIOotqmowjCKqubRn06jrWNHB3ecVCYOgbve6+dYhuhDHIWWKNVd9O49/IzJZLaESMfOeOHXEbY+McZeBzk6smUTN/e8f5bqpPw9gzaSBQa7fys9cl1pkHY5pmGCahRoCy8L3aBKwcDjExt1yS5fbHhnm4RmdV3a47UwKwwj02ktDg6N4jCGcfzdcx3VeQyS0YfjsKOu7qQtL7o6N4T0PaUUCAuR5N9ViUnbH4ZHpWZKkPaLN/SqScO7YEUzctX/PATYuGMB7ZZOE6qV0OAVlkOf5+GWHIwiCZ8iCIwiCZ5StSHVFohHC4TDYWqnb1ASKLx8cxpo+Q8NcbEinccvZ1tbO+sJR3IIODGDNpvq6JjYuncJIYyeHW8lgIMDGpSZH3fb7h95lfYpE4WaJXZJe3/S5cMs8Po7HGx0dZeOoKJbJ8sRa9Jj9fQNuOxTiIqBp4D6YngsMHpEcCuH3rNfyQqsZT1/btmGk90NYLCxrWqTy+/k9z5Ho6VAIRYOuLh6lDQaKW+ksN2NPEHEyO4X3cnyMiy+Wgeempab37N7Lxu3a9Ue3fdddd7K+93bvdttHjuC8PX78FBsXCqCbgt/B69WmHLS2oVd4VssrPUESjT3z9PNuO5nkc85gP39WmEobR9tzG8DFLC4IQtkhC44gCJ5RtiKV37TAb1pgaZu1lVdjQqGGBFqf3nqbl7199RX0rj1+/DjrW7YCRax0GkW261fdyK/Bh6IILSVcUNojiUF8L730Iuuzc7imU2tKXjuGbWMfy0GsmQGCQdxyB4J8n03Fjqo4LVPMLTcjQxgU2NyIolK8ils7wsQLORLix/DPeM5mMhn44MA/w2JhmdPe1sEA/9tokVzPbe0oCq9fdx0bZxh4L3Xr4sGDKNpQr+GMVnKopho9iDs6lrntY9q8Gh7FefCv//Yq68uk536m1dU1bFysEhPCWSG8/xXkfQCA2ga0htpacq5TJLfyB0cwaNQBraQPcWM3yDWZ2j7EptZVPU/XzMf0fHLFkB2OIAieIQuOIAieIQuOIAieUbY6nJHxMUhlMzA+zpNnDY+gnExl5lSKmzIbSJ2qCZY8C2BsDL1FMxmUf0+f4eVUr+rEukV730MTqJ3n5sUIsVkGfDzSOBjBaN0g0bmEwzyhUiSK+oUK2o7pehXsC+k6HHIdPh9pWzxhmI8UKwoGyRQoiMpGud5n8aliziQW0+/7QlNfXwuWZUJFlOuQGhPohXv99Zh4PBLmurFcDnUnsQpeCyyRwKwB+99DnZ/P5M8wGsFI8tGxUbe9avUqNi5LIrh7TvHEWgkyHyMh1MdUVnHdTCCEe4CGerzeT936aTZu+ZXL3fbxozzpu0WiwMMxovML8/2FL4Dfk6qB9Ij7dBqfcV4rIDBbXEAvf10M2eEIguAZsuAIguAZZStSWcEAWMEAgE/bBpJ8szRQr66OJ9mKxzHYMpvlZsMs2T9mmUmRbxfPnEEP2rZWNB+vXcNzw1ZWVrntaJSbXsNhIm5RkUdL8uQjeXkt8p19vuKPKK95mCqH5vn1kzYXvWjCKtvB719Qtpfmr7W0xEsz5lFlLW6p32AwAD7LgsYmHoC76loUo5oa8dlXVHDR63T/CbdtWnwu0eRm1SQ4t//MABtHRYoxIlJNTHHP5fo6FIGqq7j41rEMA0UjYRSTq6tjbFxbOyZza2xCMayqns/vf/vty27bpz2b9isxt3IwgHbsmto4G0djf6dS6J2sl3y2HcwPrnJaLu4Ze7hxnlGc89rhPPHEE7BmzRqIxWLQ0NAA9957Lxwm4QUA05N527Zt0NzcDOFwGG6//XY4ePBgkSMKlxr/9+WX4b//wz/Apvs3wZavb4HnnnmuYIzMAaEY81pwdu7cCQ8++CC8+eab0N3dDfl8HjZs2ACTk7jSf+9734Pvf//78IMf/ADefvttaGxshDvvvBOSyWSJIwuXCkeOHIE77rgDHvlvj8Df/9e/d2O7ZA4I54Oh1HwzWiBnz56FhoYG2LlzJ9x6662glILm5mbYvHkzfOtb3wKAaU/URCIB3/3ud+FrX/vaOY85Pj4O8XgcfvT0sxAOh1mQHgDPFZMnffk8H5enQZ/aN6RKeMvCLadPE9/o1pJ68fr9msWG5CA2jOLbdoqeD4deEz2GnguGlkfRvzMNoWMlaUo+YZqHR7smcjylW7BmXg8MDMA3v/FNePnll+Huu+9ekDkAgPNg5fIEWJYJkTAXQe/+y8+47ap4lLQr2TgrgPNgcoqXyxkfHSdtXAw/OsEtTDQ/Ds27NDHJj9fQgGLfjTfyINKWKzAHE73N4RAXd+tr8PqpJ/mLO37Nxn10CkXFz36O59G+rgtzAP3jP/+T256c5PMlNYX3hnpXV9dUsXF79mBA8sTYFOszzenfgu04cKxnBMbGxqCykj8DNr5oz3kwNjZd06imZto9+8SJE9Df3w8bNmxwxwSDQbjttttg165dH+dUQpkyaxavrp42U8scEEpxwUpjpRRs2bIF1q9fD6tWTfsj9PdPF1VPJLiCL5FIwKlTpwqOATD91y+TIakBNL8boXxRSsGvfzX9l3flypUAcGFzAEDmweXCBe9wNm3aBPv27YOf//znBX2645BSas5SHwDTiuh4PO7+a21tnXOcUH789H/+FHpP987ZN585ACDz4HLhgnY4Dz30ELz00kvw2muvQUsLJgJqbJw24/X390NTE0bwDgwMFPzFm+WRRx6BLVu2uK/Hx8ehtbUVQsEghEMhCAW5lyyds1Sfo1TxHME6Bsxtyi34ORT5geg/HKoHsjTTK9WfUH0U/QxAYZ0q/LxmhiTnDga5Cfh8j0GTmjnMlK5fE81zy/ue3/4vsGfPHtj6ra3w8MMPu+9fyBwAKD4PxseTYJoGOA7XdVCXgFGif0mnuJ4iXIH3ZCrFd02K6MNqazFqu72lg43r/h16IU8R5bjuApGaQv1GTw9fiM+exQRxNpmb1ZVaLm5SxyxLEqwdP8oj06PE/D9AygMDACwjNckqq/H4wTCfB/19eE0d5HdcGefXZPmvd9sfHube+KMjowDAdYulmNcORykFmzZtgh07dsArr7wCHR38wXR0dEBjYyN0d2ON7mw2Czt37oR169bNecxgMAiVlZXsn1C+KKXg+ee3w1tvvQXf/va3ob6+nvVfyBwAkHlwuTCvHc6DDz4IP/vZz+A3v/kNxGIxV16Px+MQDofBMAzYvHkzPP7449DZ2QmdnZ3w+OOPQyQSgS9+8YuL8gUEb/nJ88/DH/6wC775zW9COBx2DQepVAoqKytlDgglmdeC86Mf/QgAAG6//Xb2/vbt2+GrX/0qAAA8/PDDkEql4IEHHoCRkRG4+eab4Xe/+x3EYjGYD7lcDnK5XIGplooNJVQCTPQoKKtrzL2xK6VjKFVOlh5fF+Xo56jIUkz80T+ji0PcjM8fX7HPzaVPmes69HH09aypvrv7XwEA4LHHHmNjd+zYAffffz8ALNwcAJgW/5QymPisX/fkBMkHPcq9fxNWLRnHc0A7NnrXdq5Az+XrrlnNxv3yhZfI8VEM+cSN17Nxf3HzzW57/4H3WV+ezGPq0P3/DnCHyNUrsYTPX9/779z23X/1V2wcncJ9p3tY3wgJcLZIGZrkJC/XHAjj/LFIWWHD4vf6yqtRklmxvJP1vf/+9PfM5vKw7wj30J6LeS045+OyYxgGbNu2DbZt2zafQwuXCL/+1S+nGzMzfmpqCr7yla/Al770JXeMzAGhGBK8KQiCZ8iCIwiCZ5RttLht2wXR0Do8HEDvI275mslcFRlXSodDdSe6aEmvU9c5UT1LqXPRz9F2KRO8fi5KKT3QhZjg9ZLDsyV+9bphC41pGmCaBtTW8WTjGVKDa88eLFFsKB4Ckc2tcNvLOppZHy2fmyMlpYMhnhytYxlGX3d2YBhBezs/Hr0Ty1csZ31v7cbwgMYr0AR9y/r1bFxTPSYWO3QYyzWbAe2nSqaF/gz8JFziVC/qdwIBbsaPxvB1xiY12LQQiPYOTEzfnGhjfZ3XTt/fqak0vPCr1+BcyA5HEATPkAVHEATPKFuRyjAMMAyzwBxKt49UMtC9ZNmeU7euFRGdSooU1KypiXo26TNLmKBZ4qsSoggVeXTxp5QYRSklHtJjlroO2ldwC039fi8OluUD0zSgQXMwrCP5fsdIBHNqUk+2hhfe3MxFIBqW0Xe6320P9HGP5OtWYu7ixlp0SNRzW//yxd+47X//N3/D+tZ/GkWnE8QLuVLLWX3jTTe57VMkIvyffvhjNu6jHuz7xje+zvr8WZqkDsWmwcFRNi6XRRN/VTUm5zIMPifeJdHiR2MnWF/FTNnsNCkvXArZ4QiC4Bmy4AiC4BllK1KBMgGUWRBQSS1OiubcVaY2Dtv69t9RRCxjn9GsT0XEjQLP5RJew1QEKmU58pMcxzx5VnHPZf28xcSoUp7Rxa5Vf60nFpsVYQtF2cWB5oPWz7tsGZZufv33vOTz2Dhaok4c5wGVyQkUnWpJbuH33tvPxgV92HfCh/fkc3dyC9N/+c//yW2/8ac/sb7W5Wi1omk40iEenNzb1+e2r1uNHs/LrlzBxv32t7912x+e5Gk/AlGcS/E4Wr2SSS4CDg392W3TMkXRKL/XqTSKrCPjY8CZnhfZbGmLMh8tCILgAbLgCILgGbLgCILgGeWrwwE1/c/QPXeLmHsNzW5LdB26l6xjzy1vljIl+7U6Uux4RfQ0AKX1O8XGnW9e+1I6nFLeyqX0QMWON0d6Mk+wwAATDIjHeE2lYAB1H8va0XM3v47fu1MfoZ7ij396l/UlEqibGRgcdNsVkSo2ro+UgJ5Mjrrttw8cYOM2bkQdzqiWInX0IHpD2ySxWQ64Gf/sGOpc4gOYWKuuhtel+vw9GD3+zrvvsL7+QdQD0VplDQ38GPkc6ihpXTQT+FyPRdB0n7dHWF8qnZk5luhwBEEoM2TBEQTBM8pWpEqlJwAMG2ybezBGoxhYZ1CPXM1s61CxREuKlSNbSZ4jmJsoaeBlKS9hntNYywtcJGBTN0EXS5ili0PUy/l8vYl16PWXCgYtlcRsNi/vxyhrdl4EfD6wTANaGnlS9eFBFFlmyxQBANx6WyMbt2cvlmt+/Q1epsb0Y/nm/QePum1b8by9joP3IVaF4sXYIE9o9eP/hQUFWloaWF97M4p9joX3rLf/DBvXGcBA0TQxn/f29rNxtaSs8IrOlawvZxKROYmfU4qLb02NmOxrcADN3cNneRKzNCm/FbB4YGu0aloszWb0GmlzIzscQRA8QxYcQRA8o2xFqkgkCuFwuKA8iGUV8abV1k5WraUgV+/cuYV1cahYjppSnsaOXi6DWCSoiHah59LzGFOK5U++UMuZKmHpm+1abJEqkagDn2VBMsnL6r75pzfd9vAwWk7u+Az3/j1wEL2GV91wLeuLV6N3rUlKodTUc3FotqooAEBvH5YBVlqp5aY6tAIdPcJzFWfyeP0NLVgux9Ksrnv2vue2K9ZgCWMf8N9BOILif0UFLxfUSbySe8/gfMnlUmzcyAgGb9LyRjW13CJYW4fXOzbBxcih4WnrXlasVIIglBuy4AiC4Bmy4AiC4Bllq8OxzCD4rBA4WolZ6lFM9Rm6boPpKfSIa1bqt7gOgpqPqTla11vQEr56X8BCr02aTMzn496cVIamta10fQvVzejmeapnKZVnmed7Lv79WaIu7Ri27U1OYzANANOAI0ePsLfHxkfd9iiJYD5wkOtObAfdKnxcDQJBUpdp5So0R1/RyvP2TkxgtLQ/jPfEp82d5W1ounfUFOvLkWRdE0nihRzgz7cijmbnwWH0kvYrfvEjo+gZvWx5O+sLhHBurbr2Brf94Yf8HmbTaHZf1o61p4aHRtm4ZBLN5FNTXJc2+/zPdx7IDkcQBM+QBUcQBM8oX5HK8s/80xJrwdz5g1kyLsAtP0Bh2GExMUI3VftJmVRqdi/cPpYoA0w+R89LA+f0z/FATn4mWs7E1vI9F5MO9beLeSjr4hszi9v8KLNin17aeKHJZjPgWCb09fNgSPqsamqq3HYmwz3Tw1E0H6fSXBxITuL9S+WT2M5xcShMghfr6tH0bWpiZjiCYk/nlbxMzL6De912LcnPPDwxysZliegVi6NZ/OB7h9i4kB/Plcvz660mntctrXgdVy6/ip8rg+eiM6Kqhpdk7h/AxGWnTn7I+jKZ6fmoz+diyA5HEATPkAVHEATPkAVHEATPKFsdjs9ngc9nFdZlUnPLiqWSTBWMdeYObShVA8oiidgtLSl7qeTo1FxfKslWsXpTpuYW4JCaQQHNFUBB8eugUB2UQaR3O1+q5pUeHmLM/L+4f7N8AR/4LAtyWtI0h3xXWqNqKsUThYdJkvKKOC9129KGdaomU6jDmcrwaOlAGEMHensxkjykJWUzHXSPOHWS12+KRlEPRPVh4QiPvg6G8XqpK8CxY0fZuM/fdZfb/vPZPtZHXSImxtD0ffW1XIdz7dUY6vG/X/ip21Ymv9c33ohhH7GKStY3W2Y5JzocQRDKjbLb4cz+ZU6lpjXvpqntBBZghwNFHOtK7XBUkfPq51rwHY5e4oZYpvQcQBeywzmfawDQ8gsB3sJUKnXO810Is8fLzwTD5m3d8ZA6ORIHTW0c7ctpAYYZksOFljnRS57wcdjWst+y6pP6MRzqbOoj5zKKn8vM4PPN5fkzSxGnvbSWi8ZPq2AqHDc5yYM3Fdkt0+vVdzipFDmXVmFzdmcz+/+55oGhFjvcd5709vZCa2vruQcKZUVPTw+0tLSce+B5IvPg0uRc86DsFhzHceDMmTOglIK2tjbo6emBysrKc39wiTM+Pg6tra1ldz+UUpBMJqG5ufm8016cDzIPCinXOQBw/vOg7EQq0zShpaUFxmey3ldWVpbdzb2YlOP9iMfj5x40T2QeFKdc78X5zANRGguC4Bmy4AiC4Bllu+AEg0F49NFHCyopXK5crvfjcv3ec7EU7kXZKY0FQVi6lO0ORxCEpYcsOIIgeIYsOIIgeIYsOIIgeEbZLjhPPfUUdHR0QCgUgq6uLnj99dcv9iUtOk888QSsWbMGYrEYNDQ0wL333guHDx9mY5RSsG3bNmhuboZwOAy33347HNQShy8VZA4swTmgypAXXnhB+f1+9dxzz6lDhw6pr3/96yoajapTp05d7EtbVO666y61fft2deDAAbVnzx51zz33qLa2NjUxMeGOefLJJ1UsFlMvvvii2r9/v7rvvvtUU1OTGh8fv4hXvvDIHFiac6AsF5y1a9eqjRs3sveuueYatXXr1ot0RReHgYEBBQBq586dSimlHMdRjY2N6sknn3THpNNpFY/H1dNPP32xLnNRkDkwzVKbA2UnUmWzWdi9ezds2LCBvb9hwwbYtWvXRbqqi8PY2HS9pZqZpNgnTpyA/v5+dm+CwSDcdtttS+reyBxAltocKLsFZ3BwEGzbhkQiwd5PJBLQ399/ka7Ke5RSsGXLFli/fj2sWrUKAMD9/kv93sgcmGYpzoGyixafZa6EWsXKmyxFNm3aBPv27YM33nijoO9yuTeXy/csxlKcA2W3w6mrqwPLsgpW64GBgYJVfany0EMPwUsvvQSvvvoqS2bU2NgIALDk743MgaU7B8puwQkEAtDV1QXd3d3s/e7ubli3bt1FuipvUErBpk2bYMeOHfDKK69AR0cH6+/o6IDGxkZ2b7LZLOzcuXNJ3RuZA0t4Dlw8fXVxZk2iP/nJT9ShQ4fU5s2bVTQaVSdPnrzYl7ao3H///Soej6vf//73qq+vz/03NTXljnnyySdVPB5XO3bsUPv371df+MIXLhmT6HyQObA050BZLjhKKfXDH/5Qtbe3q0AgoD75yU+6ZsGlDExX5S34t337dneM4zjq0UcfVY2NjSoYDKpbb71V7d+//+Jd9CIic2DpzQFJTyEIgmeUnQ5HEISliyw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4hiw4giB4xv8HQJ811RrmsSIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first 2 images of noisy data\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(2,4,1)\n",
    "ax1.imshow(noisy_imgs[0]/255)\n",
    "ax2 = fig.add_subplot(2,4,2)\n",
    "ax2.imshow(noisy_imgs[1]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44346c10",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970e59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the images\n",
    "\n",
    "# noisy_imgs = noisy_imgs/255.0\n",
    "# clean_imgs = clean_imgs/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0097b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now comes the most essential step of pre-processing, which is applicable only in this case as we aim to use \n",
    "# machine learning for image classification. As we will be using the ML algorithms from sklearn, there is a need \n",
    "# to reshape the images of the dataset to a two-dimensional array. This is because sklearn expects a 2D array as \n",
    "# input to the fit() function which will be called on the model during training. Thus, the images of the test \n",
    "# dataset should also be resized to 2D arrays as the model will be trained with this input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00a2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "# nsamples, nx, ny, nrgb = noisy_imgs.shape\n",
    "# imgs_train = noisy_imgs.reshape((nsamples,nx*ny*nrgb))\n",
    "# print(imgs_train.shape)\n",
    "\n",
    "# nsamples, nx, ny, nrgb = clean_imgs.shape\n",
    "# imgs_test = clean_imgs.reshape((nsamples,nx*ny*nrgb))\n",
    "# print(imgs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7ad9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "\n",
    "# RGB histogram dataset construction - train data\n",
    "\n",
    "no_bins_train = 6\n",
    "bins_train = np.linspace(0, 255, no_bins_train) # the range of the rgb histogram\n",
    "img_feature_train = np.empty((noisy_imgs.shape[0], 3*(len(bins_train)-1)))\n",
    "i = 0\n",
    "\n",
    "for i in range(noisy_imgs.shape[0]):\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1_tr = np.histogram(noisy_imgs[i][:,:,0],bins=bins_train)[0] \n",
    "    feature2_tr = np.histogram(noisy_imgs[i][:,:,1],bins=bins_train)[0]\n",
    "    feature3_tr = np.histogram(noisy_imgs[i][:,:,2],bins=bins_train)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    img_feature_train[i,] = np.concatenate((feature1_tr, feature2_tr, feature3_tr), axis=None)\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "# RGB histogram dataset construction - test data\n",
    "no_bins_test = 6\n",
    "bins_test = np.linspace(0, 255, no_bins_test) # the range of the rgb histogram\n",
    "img_feature_test = np.empty((clean_imgs.shape[0], 3*(len(bins_test)-1)))\n",
    "i = 0\n",
    "\n",
    "for i in range(clean_imgs.shape[0]):\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1_ts = np.histogram(clean_imgs[i][:,:,0],bins=bins_test)[0] \n",
    "    feature2_ts = np.histogram(clean_imgs[i][:,:,1],bins=bins_test)[0]\n",
    "    feature3_ts = np.histogram(clean_imgs[i][:,:,2],bins=bins_test)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    img_feature_test[i,] = np.concatenate((feature1_ts, feature2_ts, feature3_ts), axis=None)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d53bed",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d0c57",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7130136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed0aa88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.32      0.36      1299\n",
      "           1       0.29      0.19      0.23      1508\n",
      "           2       0.06      0.20      0.09       288\n",
      "           3       0.09      0.19      0.12       487\n",
      "           4       0.48      0.24      0.32      1969\n",
      "           5       0.17      0.21      0.19       731\n",
      "           6       0.34      0.26      0.30      1369\n",
      "           7       0.03      0.26      0.05       111\n",
      "           8       0.43      0.28      0.34      1584\n",
      "           9       0.13      0.19      0.15       654\n",
      "\n",
      "    accuracy                           0.24     10000\n",
      "   macro avg       0.24      0.23      0.21     10000\n",
      "weighted avg       0.33      0.24      0.27     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "lr_model = LogisticRegression(random_state=0).fit(img_feature_train, noisy_labels)\n",
    "\n",
    "# Predict\n",
    "pred_lr_test= lr_model.predict(img_feature_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(pred_lr_test, clean_labels)) # accuracy = 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d8df2",
   "metadata": {},
   "source": [
    "### Implementing a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199f29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21607765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.17      0.17       992\n",
      "           1       0.12      0.12      0.12       999\n",
      "           2       0.15      0.15      0.15      1015\n",
      "           3       0.10      0.11      0.11       936\n",
      "           4       0.15      0.14      0.14      1062\n",
      "           5       0.13      0.12      0.12      1039\n",
      "           6       0.13      0.13      0.13      1019\n",
      "           7       0.15      0.15      0.15       971\n",
      "           8       0.15      0.16      0.15       966\n",
      "           9       0.15      0.15      0.15      1001\n",
      "\n",
      "    accuracy                           0.14     10000\n",
      "   macro avg       0.14      0.14      0.14     10000\n",
      "weighted avg       0.14      0.14      0.14     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=0).fit(img_feature_train, noisy_labels)\n",
    "\n",
    "# Predict\n",
    "pred_dt_test= dt_model.predict(img_feature_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(pred_dt_test, clean_labels)) # accuracy = 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83f240",
   "metadata": {},
   "source": [
    "### Implementing a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5f7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18218cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.34      0.35      1015\n",
      "           1       0.32      0.26      0.29      1188\n",
      "           2       0.19      0.22      0.20       908\n",
      "           3       0.14      0.16      0.15       924\n",
      "           4       0.26      0.23      0.25      1142\n",
      "           5       0.19      0.19      0.19       957\n",
      "           6       0.30      0.29      0.29      1059\n",
      "           7       0.22      0.25      0.23       891\n",
      "           8       0.29      0.32      0.30       935\n",
      "           9       0.29      0.29      0.29       981\n",
      "\n",
      "    accuracy                           0.26     10000\n",
      "   macro avg       0.26      0.25      0.25     10000\n",
      "weighted avg       0.26      0.26      0.26     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=0).fit(img_feature_train, noisy_labels)\n",
    "\n",
    "# Predict\n",
    "pred_rf_test= rf_model.predict(img_feature_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(pred_rf_test, clean_labels)) # accuracy = 0.26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d374a",
   "metadata": {},
   "source": [
    "### Implementing a KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d62a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea8e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.27      0.30      1237\n",
      "           1       0.31      0.20      0.24      1546\n",
      "           2       0.21      0.19      0.20      1101\n",
      "           3       0.15      0.15      0.15      1030\n",
      "           4       0.20      0.20      0.20       967\n",
      "           5       0.15      0.15      0.15       900\n",
      "           6       0.23      0.25      0.24       946\n",
      "           7       0.15      0.22      0.18       706\n",
      "           8       0.21      0.27      0.24       784\n",
      "           9       0.19      0.24      0.21       783\n",
      "\n",
      "    accuracy                           0.21     10000\n",
      "   macro avg       0.21      0.21      0.21     10000\n",
      "weighted avg       0.22      0.21      0.22     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 20).fit(img_feature_train, noisy_labels)\n",
    "\n",
    "# Predict\n",
    "pred_knn_test= knn_model.predict(img_feature_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(pred_knn_test, clean_labels)) # accuracy = 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1ad37",
   "metadata": {},
   "source": [
    "### Implementing a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c6166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40e1b814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.31      0.38      1593\n",
      "           1       0.30      0.22      0.25      1313\n",
      "           2       0.13      0.28      0.17       457\n",
      "           3       0.03      0.17      0.05       164\n",
      "           4       0.44      0.21      0.28      2109\n",
      "           5       0.03      0.23      0.05       126\n",
      "           6       0.28      0.27      0.28      1097\n",
      "           7       0.03      0.34      0.06        98\n",
      "           8       0.18      0.28      0.22       650\n",
      "           9       0.55      0.23      0.32      2393\n",
      "\n",
      "    accuracy                           0.25     10000\n",
      "   macro avg       0.25      0.25      0.21     10000\n",
      "weighted avg       0.39      0.25      0.29     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "nb_model = GaussianNB().fit(img_feature_train, noisy_labels)\n",
    "\n",
    "# Predict\n",
    "pred_nb_test= nb_model.predict(img_feature_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(pred_nb_test, clean_labels)) # accuracy = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb01783",
   "metadata": {},
   "source": [
    "### Implementing Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfef5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Normalizing the image for faster training of the model\n",
    "\n",
    "img_train = noisy_imgs/255.0\n",
    "print(img_train.shape)\n",
    "img_test=clean_imgs/255.0\n",
    "print(img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e89f7276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 04:01:24.901265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from numpy.random import seed\n",
    "seed(18)\n",
    "tf.random.set_seed(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0603f",
   "metadata": {},
   "source": [
    "#### 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf51eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 21:05:51.007031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cnn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca1fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer 1\n",
    "# Conv2D means convolution takes place on 2 axis. It extends the convolution to three strata, Red, Green and Blue.\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, padding=\"same\", \n",
    "                                         activation= \"relu\", input_shape=[32,32,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f07047fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPoolingLayer\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02ec833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening Layer\n",
    "cnn_model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "766e979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droput Layer - to prevent overfitting, a dropout layer is added\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43bfe6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first fully connected layer\n",
    "cnn_model.add(tf.keras.layers.Dense(units=64, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad46432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "cnn_model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf5b5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model - we need to take loss function into account.\n",
    "# Sparse Categorical Cross-Entropy(scce) is used when the classes are mutually exclusive\n",
    "# We will be using the generally used Adam Optimizer. Adam is an abbreviation for “Adaptive Learning rate Method”. \n",
    "# This optimizer uses the initial of the gradient to adapt to the learning rate. \n",
    "# Adam is now used instead of the stochastic gradient descent, which is used in ML, \n",
    "# because it can update the weights after each iteration.\n",
    "\n",
    "cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", \n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "519ef632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 2.2716 - accuracy: 0.1566\n",
      "Epoch 2/8\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.2292 - accuracy: 0.2001\n",
      "Epoch 3/8\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 2.2039 - accuracy: 0.2231\n",
      "Epoch 4/8\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 2.1729 - accuracy: 0.2380\n",
      "Epoch 5/8\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 2.1398 - accuracy: 0.2549\n",
      "Epoch 6/8\n",
      "1250/1250 [==============================] - 48s 38ms/step - loss: 2.1043 - accuracy: 0.2702\n",
      "Epoch 7/8\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 2.0653 - accuracy: 0.2864\n",
      "Epoch 8/8\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 2.0250 - accuracy: 0.3018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e0fbc2af0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(img_train, noisy_labels, epochs= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33236e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 7ms/step - loss: 1.8697 - accuracy: 0.4102\n",
      "0.41019999980926514\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = cnn_model.evaluate(img_test, clean_labels) # accuracy: 0.4102\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken (in mins) to run code: \", (end - start)/60)\n",
    "print(\"test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most problems, one could probably get decent performance (even without a second optimization step) \n",
    "# by setting the hidden layer configuration using just two rules: \n",
    "# (i) the number of hidden layers equals one; and \n",
    "# (ii) the number of neurons in that layer is the mean of the neurons in the input and output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e911f",
   "metadata": {},
   "source": [
    "#### 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "911da62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "cnn_model_0 = tf.keras.models.Sequential()\n",
    "cnn_model_0.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, padding=\"same\", \n",
    "                                         activation= \"relu\", input_shape=[32,32,3]))\n",
    "cnn_model_0.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "cnn_model_0.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))\n",
    "cnn_model_0.add(tf.keras.layers.Flatten())\n",
    "cnn_model_0.add(tf.keras.layers.Dropout(0.2))\n",
    "cnn_model_0.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "cnn_model_0.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "cnn_model_0.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", \n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9ab9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1250/1250 [==============================] - 87s 69ms/step - loss: 2.2652 - accuracy: 0.1662\n",
      "Epoch 2/8\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 2.2143 - accuracy: 0.2167\n",
      "Epoch 3/8\n",
      "1250/1250 [==============================] - 85s 68ms/step - loss: 2.1773 - accuracy: 0.2376\n",
      "Epoch 4/8\n",
      "1250/1250 [==============================] - 91s 73ms/step - loss: 2.1267 - accuracy: 0.2612\n",
      "Epoch 5/8\n",
      "1250/1250 [==============================] - 147s 118ms/step - loss: 2.0625 - accuracy: 0.2840\n",
      "Epoch 6/8\n",
      "1250/1250 [==============================] - 112s 89ms/step - loss: 1.9816 - accuracy: 0.3162\n",
      "Epoch 7/8\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 1.8940 - accuracy: 0.3428\n",
      "Epoch 8/8\n",
      "1250/1250 [==============================] - 102s 82ms/step - loss: 1.7985 - accuracy: 0.3773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e0fca2790>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_0.fit(img_train, noisy_labels, epochs= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b956df83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 1.9366 - accuracy: 0.3634\n",
      "0.36340001225471497\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = cnn_model_0.evaluate(img_test, clean_labels) # accuracy - 0.3634\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken (in mins) to run code: \", (end - start)/60)\n",
    "print(\"test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd4f1a",
   "metadata": {},
   "source": [
    "#### 2 layers and both filters 64, units 32 - 0.3930, both  filters 64, units 64 - 0.3859, filter1 64, filter2 32 units 32 - 0.3859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "978ae09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1250/1250 [==============================] - 205s 163ms/step - loss: 2.2833 - accuracy: 0.1371\n",
      "Epoch 2/8\n",
      "1250/1250 [==============================] - 189s 151ms/step - loss: 2.2532 - accuracy: 0.1747\n",
      "Epoch 3/8\n",
      "1250/1250 [==============================] - 239s 191ms/step - loss: 2.2316 - accuracy: 0.1969\n",
      "Epoch 4/8\n",
      "1250/1250 [==============================] - 205s 164ms/step - loss: 2.2085 - accuracy: 0.2162\n",
      "Epoch 5/8\n",
      "1250/1250 [==============================] - 184s 147ms/step - loss: 2.1836 - accuracy: 0.2300\n",
      "Epoch 6/8\n",
      "1250/1250 [==============================] - 333s 267ms/step - loss: 2.1526 - accuracy: 0.2473\n",
      "Epoch 7/8\n",
      "1250/1250 [==============================] - 345s 276ms/step - loss: 2.1241 - accuracy: 0.2564\n",
      "Epoch 8/8\n",
      "1250/1250 [==============================] - 216s 173ms/step - loss: 2.0883 - accuracy: 0.2713\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 1.8950 - accuracy: 0.3930\n",
      "time taken to run code:  1931.0079810619354\n",
      "test accuracy:  0.3930000066757202\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "cnn_model_1 = tf.keras.models.Sequential()\n",
    "cnn_model_1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3, padding=\"same\", \n",
    "                                         activation= \"relu\", input_shape=[32,32,3]))\n",
    "cnn_model_1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "cnn_model_1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))\n",
    "cnn_model_1.add(tf.keras.layers.Flatten())\n",
    "cnn_model_1.add(tf.keras.layers.Dropout(0.2))\n",
    "cnn_model_1.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "cnn_model_1.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "cnn_model_1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", \n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "cnn_model_1.fit(img_train, noisy_labels, epochs= 8)\n",
    "\n",
    "test_loss, test_accuracy = cnn_model_1.evaluate(img_test, clean_labels)\n",
    "\n",
    "end = time.time()\n",
    "print(\"time taken (in mins) to run code: \", (end - start)/60)\n",
    "print(\"test accuracy: \", test_accuracy) # accuracy - 0.3930"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1413e",
   "metadata": {},
   "source": [
    "#### multiple hidden layers (4 layers) - gives best accuracy so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d507298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1250/1250 [==============================] - 100s 79ms/step - loss: 2.2794 - accuracy: 0.1451\n",
      "Epoch 2/8\n",
      "1250/1250 [==============================] - 112s 89ms/step - loss: 2.2437 - accuracy: 0.1872\n",
      "Epoch 3/8\n",
      "1250/1250 [==============================] - 112s 90ms/step - loss: 2.2255 - accuracy: 0.2035\n",
      "Epoch 4/8\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 2.2051 - accuracy: 0.2194\n",
      "Epoch 5/8\n",
      "1250/1250 [==============================] - 106s 85ms/step - loss: 2.1852 - accuracy: 0.2346\n",
      "Epoch 6/8\n",
      "1250/1250 [==============================] - 108s 86ms/step - loss: 2.1631 - accuracy: 0.2447\n",
      "Epoch 7/8\n",
      "1250/1250 [==============================] - 105s 84ms/step - loss: 2.1383 - accuracy: 0.2567\n",
      "Epoch 8/8\n",
      "1250/1250 [==============================] - 106s 85ms/step - loss: 2.1082 - accuracy: 0.2701\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.7703 - accuracy: 0.4808\n",
      "time taken (in mins) to run code:  14.414799662431081\n",
      "test accuracy:  0.48080000281333923\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "cnn_model_2 = tf.keras.models.Sequential()\n",
    "cnn_model_2.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, padding=\"same\", \n",
    "                                         activation= \"relu\", input_shape=[32,32,3]))\n",
    "cnn_model_2.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "cnn_model_2.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))\n",
    "cnn_model_2.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "cnn_model_2.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "cnn_model_2.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))\n",
    "cnn_model_2.add(tf.keras.layers.Flatten())\n",
    "cnn_model_2.add(tf.keras.layers.Dropout(0.2))\n",
    "cnn_model_2.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "cnn_model_2.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "cnn_model_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Adam\", \n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "cnn_model_2.fit(img_train, noisy_labels, epochs= 8)\n",
    "test_loss, test_accuracy = cnn_model_2.evaluate(img_test, clean_labels)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken (in mins) to run code: \", (end - start)/60)\n",
    "print(\"test accuracy: \", test_accuracy) # accuracy - 0.4808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b49892",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Do not run the hyperparameter tuning code below!!! I ran it for 17 hours and it was still running#######\n",
    "#### I am working on a better code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49a219",
   "metadata": {},
   "source": [
    "### The hyperparameters to tune in a CNN are the number of neurons, activation function, optimizer, batch size, and epochs. One other hyperparameter is the number of layers\n",
    "\n",
    "1. Number of neurons - The first hyperparameter to tune is the number of neurons in each hidden layer. The number of neurons should be adjusted to the solution complexity. The task with a more complex level to predict needs more neurons.\n",
    "\n",
    "2. Activation function - activation function is a parameter in each layer.\n",
    "\n",
    "3. Optimizer - The layers of a neural network are compiled and an optimizer is assigned. The optimizer is responsible to change the learning rate and weights of neurons in the neural network to reach the minimum loss function. Optimizer is very important to achieve the possible highest accuracy or minimum loss. There are 7 optimizers to choose from. Each has a different concept behind it.\n",
    "\n",
    "4. Learning rate - One of the hyperparameters in the optimizer is the learning rate. We will also tune the learning rate. Learning rate controls the step size for a model to reach the minimum loss function. A higher learning rate makes the model learn faster, but it may miss the minimum loss function and only reach the surrounding of it. A lower learning rate gives a better chance to find a minimum loss function. As a tradeoff lower learning rate needs higher epochs, or more time and memory capacity resources.\n",
    "\n",
    "5. Batch size - If the observation size of the training dataset is too large, it will definitely take a longer time to build the model. To make the model learn faster, we can assign batch size so that not all of the training data are given to the model at the same time. Batch size is the number of training data sub-samples for the input.\n",
    "\n",
    "6. Epoch - The number of times a whole dataset is passed through the neural network model is called an epoch. One epoch means that the training dataset is passed forward and backward through the neural network once. A too-small number of epochs results in underfitting because the neural network has not learned much enough. The training dataset needs to pass multiple times or multiple epochs are required. On the other hand, too many epochs will lead to overfitting where the model can predict the data very well, but cannot predict new unseen data well enough. The number of epoch must be tuned to gain the optimal result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "611d2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c78fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 04:22:47.990805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 04:22:47.990805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 04:22:47.990807: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 04:22:47.990805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "2023-03-18 04:23:14.811413: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "2023-03-18 04:23:19.253535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "2023-03-18 04:23:21.831221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 04:23:21.933105: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "/Users/srushtisanghavi/opt/anaconda3/lib/python3.9/site-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xg/cm7r8_fn25qf0945gy5q7mjc0000gn/T/ipykernel_10468/459125673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Perform the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed(18)\n",
    "tf.random.set_seed(18)\n",
    "# tune the hyperparameters of a neural network using Grid Search, for 4 hidden layers. \n",
    "start = time.time()\n",
    "# Create function\n",
    "def cnn_hyprtune_model(dropout_rate=0.0, filters=32, kernel_size=(3, 3), units = 32):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', \n",
    "                                     input_shape=(32, 32, 3)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(units = units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the Keras classifier for scikit-learn\n",
    "kc_model = KerasClassifier(build_fn=cnn_hyprtune_model, verbose=0, dropout_rate=None, filters=None, \n",
    "                           kernel_size=None, units = None)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.0, 0.25, 0.5],\n",
    "    'filters': [32, 64],\n",
    "    'kernel_size': [(3, 3), (5, 5)],\n",
    "    'epochs': [10,20,30],\n",
    "    'batch_size': [100,300,500],\n",
    "    'units': [32,64,128]\n",
    "}\n",
    "\n",
    "# Perform the grid search\n",
    "grid = GridSearchCV(estimator=kc_model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(img_train, noisy_labels)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken (in mins) to run code: \", (end - start)/60)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "#This code uses GridSearchCV from scikit-learn to perform a grid search over the specified hyperparameters. The create_model function defines the CNN architecture, and the KerasClassifier function creates a wrapper around the model so that it can be used in scikit-learn's grid search. The param_grid variable defines the hyperparameters to search over, and the n_jobs argument specifies how many CPUs to use for parallel processing (-1 means to use all available CPUs). Finally, the fit method performs the grid search on the training data. Once the search is complete, the best hyperparameters and corresponding accuracy are printed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046c613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
